= Getting Started
include::_attributes.adoc[]
:profile: acs

We will install ACS thought the RHACS Operator and afterwards we will install an small demo that will serve examples to our workshop.

NOTE: You can request in RHPDS the environment already installed (including the demo) - Go to Multi-Product Demo -> Openshift 4 Advanced Cluster Security 3

[#install_acs_operator]
== RHACS Operator Installation

. Find and the Advanced Cluster Security Operator from the Operator Hub.
+
image::install/00_operator_hub.png[ACS Operator 1, 800]

. Install the selected operator by clicking on the ``Install`` button.
+
image::install/01_select_acs_operator.png[ACS Operator 2, 800]

. Confirm default installation parameters (auto update, ``latest channel``, ``rhacs-operator`` namespace).
+
image::install/02_install_acs_operator.png[ACS Operator 3, 800]

. Wait for completion, the installation will take a few seconds.
+
image::install/03_wait_for_completion.png[ACS Operator 4, 800]

. Access the now ready operator by clicking on the ``View Operator`` button.
+
image::install/04_operator_ready.png[ACS Operator 5, 800]

[#install_acs_central]
== RHACS Central Cluster Installation

In this section we will deploy the Central component in the lab cluster. The Central is made up two main deployments:

* The ``central`` service, which exposes api and console and communicates with Sensors on secured clusters.

* The ``scanner`` service, which has the role of scanning the deployed pods images.

Log in to your OpenShift cluster and create a new ``stackrox`` namespace (using the web console or the cli as follows). We will install our components here.

[.console-input]
[source,bash,subs="attributes+,+macros"]	
----	
oc new-project stackrox	
----

The following is an example of the central custom resource. You can do this in two ways, via the web console or via the CLI.

[.console-input]
[source,yaml,subs="attributes+,+macros"]	
----	
apiVersion: platform.stackrox.io/v1alpha1
kind: Central
metadata:
  name: stackrox-central-services
  namespace: stackrox
spec:
  central:
    exposure:
      loadBalancer:
        enabled: false
        port: 443
      nodePort:
        enabled: false
      route:
        enabled: true
    persistence:
      persistentVolumeClaim:
        claimName: stackrox-db
  egress:
    connectivityPolicy: Online
  scanner:
    analyzer:
      scaling:
        autoScaling: Enabled
        maxReplicas: 5
        minReplicas: 2
        replicas: 3
    scannerComponent: Enabled	
----

[#install_acs_central_web_console]
=== With Web Console

. From the operator _ready screen_ by clicking on ``View Operator`` or navigating to the **Operators → Installed Operators** page. Then, under the **Provided APIs** section, select ``Create Central`` on the ``Central`` API:
+
image::install/04_1_create_central_resource.png[ACS Operator 51, 800]

. Check the ``YAML`` radio button and paste the ``Central`` CR you see below and click on the ``Create`` button.
+
image::install/04_2_create_central_resource.png[ACS Operator 52, 800]

. You can check the progress by switching to the `Developer` perspective, in the `Topology` menu.
+
image::install/04_3_create_central_resource.png[ACS Operator 53, 800]

You can also do the same using the ``Developer`` perspective:

. Within the ``stackrock`` project selected, **+Add → Import YAML**
+
image::install/04_11_create_central_resource.png[ACS Operator 511, 800]

. Paste the YAML content and click on the ``Create`` button:
+
image::install/04_22_create_central_resource.png[ACS Operator 512, 800]


[#install_acs_central_oc_client]
=== With OC client

. Create the ``central`` custom resource using the template file provided in this repository.
+
[.console-input]
[source,bash,subs="attributes+,+macros"]	
----	
oc apply -f stackrox-central-services.yaml -n stackrox
----

. Monitor the installation using the watch option:
+
[.console-input]
[source,bash,subs="attributes+,+macros"]	
----	
oc get pods -n stackrox -w
----

=== RHACS login

. Once the installation is complete, obtain and copy the generated admin password from the ``central-htpasswd`` secret.
.. Using the command line:
+
[.console-input]
[source,bash,subs="attributes+,+macros"]	
----	
oc -n stackrox get secret central-htpasswd -o go-template='{{index .data "password" | base64decode}}'
----
.. Using the web console, **Secrets** view from the ``Developer`` perspective (search for ``central-htpasswd`` secret):
+
image::install/05_1_login_password.png[ACS Operator 61, 800]

. Extract the hostname of the generated route from the command line as follows or using the ``Topology`` view from the web console.
+
[.console-input]
[source,bash,subs="attributes+,+macros"]	
----	
oc get routes/central -n stackrox -o jsonpath='{.spec.host}'
----

. Login to https://<route_hostname> using the ``admin`` username and the password extracted before.
+
image::install/05_2_login.png[ACS Operator 62, 800]

[#config_acs_securedcluster]
== RHACS Secured Cluster Configuration

To import a cluster into ACS, you need to generate a cluster init bundle containing TLS secrets for Sensor, Collectors, and Admission Controllers.

[#config_acs_securedcluster_init_bundle]
=== Generating an init bundle by using the RHACS portal

. Generate the cluster init bundle by accessing the ``Integration`` subsection in the ``Platform Configuration`` section 
+
image::install/06_acs_integrations.png[ACS Operator 7, 800]

. Generate the bundle with a unique cluster name, in our case, ``demo-cluster``
+
image::install/07_generate_cluster_init_bundle.png[ACS Operator 8, 800]

. Download the cluster init bundle secret.
+
image::install/08_download_cluster_init_bundle_secret.png[ACS Operator 9, 800]

. Apply the cluster init bundle secret on the target secured cluster
+
[.console-input]
[source,bash,subs="attributes+,+macros"]	
----	
oc apply -f ~/Downloads/demo-cluster-cluster-init-secrets.yaml -n stackrox
----
+
[TIP]
====
You can open the yaml file, copy the content and paste it to the web console using the **+Add → Import YAML** shortcut. As you are ``cluster-admin`` and all the object have the `namespace` key set you will get all the object created in their respective namespaces regrardless the project you choose in the web console (all projects or whatever).
====

[#config_acs_securedcluster_install_scs]
=== Installing secured cluster services

NOTE: This workshop uses the same cluster as central and secured cluster. In a real time scenario there will be many different secured clusters. Please ensure to install the ACS Operator in all the secured cluster in order to manage the SecuredCluster CR.

The ``SecuredCluster`` custom resource is quite simple. The following example shows the configuration for a ``demo-cluster`` target. Notice the ``collector`` configuration, with the collection method set to ``KernelModule``. The alternative collection approach would be ``eBPF``. The ``TolerateTaints`` lets the Collector daemonset be deployed also on nodes with special taints, like the ODF nodes.

[.console-input]
[source,yaml,subs="attributes+,+macros"]	
----	
apiVersion: platform.stackrox.io/v1alpha1
kind: SecuredCluster
metadata:
  name: stackrox-secured-cluster-services
  namespace: stackrox
spec:
  admissionControl:
    listenOnCreates: true
    listenOnEvents: true
    listenOnUpdates: true
  clusterName: demo-cluster
  perNode:
    collector:
      collection: KernelModule
      imageFlavor: Regular
    taintToleration: TolerateTaints
----

NOTE: Check the settings of the https://docs.openshift.com/acs/installing/install-ocp-operator.html#addmission-controller-settings_install-ocp-operator[SecuredCluster operator documentation] for more information.

. Create the Secured Cluster custom Resource using (and optionally custumizing) the example provided in the repository.
+
[.console-input]
[source,bash,subs="attributes+,+macros"]	
----	
oc apply -f stackrox-secured-cluster-services.yaml -n stackrox
----
+
Or using the web console, in the ACS opertator view, as follows:
+
.. Under the Provided APIs section, select Create instance on the Secured Cluster API
+
image::install/09_create_secured_cluster_resource.png[ACS Operator 9, 800]

.. And then copy & paste the yaml content
+
image::install/10_create_secured_cluster_resource_yaml.png[ACS Operator 10, 800]

+
Or as in the previous section, with the **+Add → Import YAML** path.

. Monitor the installation using the watch option (or using the web console ``Topology`` view from the ``Developer`` perspective as mentioned before):
+
[.console-input]
[source,bash,subs="attributes+,+macros"]	
----	
oc get pods -n stackrox -w
----

. At the end of the installation, go to the central console and check the correct attachment of the secured cluster. 
+
image::install/11_verify_cluster_list.png[ACS Operator 11, 800]

[#deploy_demo_acs] 
== Deploying Demo in RHACS - Mandatory

IMPORTANT: Independent of which option to install you used, you need to deploy the ACS Demo into your cluster.

. Download the repo with the demo:
+
[.console-input]
[source,bash,subs="attributes+,+macros"]	
----
ansible-galaxy collection install kubernetes.core
pip install kubernetes jmespath
git clone https://github.com/rh-mobb/rhacs-demo
cd rhacs-demo
----

. Apply the ansible demo into the cluster:
+
WARNING: you must be logged to the OpenShift cluster before you execute the playbook.
+
[.console-input]
[source,bash,subs="attributes+,+macros"]	
----
ansible-playbook rhacs-demo.yaml -e stackrox_central_admin_password=[your_pass]<1>
----
<1> The same password you obtained in the step 1 of the ``ACS login`` section.

. After the Playbook execution (and if everything worked properly), the output will be the following:
+
[.console-output]
[source,bash,subs="attributes+,+macros"]	
----	
TASK [ocp4_workload_stackrox_demo_apps : post_workload tasks complete] ********************************************************
ok: [localhost] => {
    "msg": "Post-Workload Tasks completed successfully."
}
----

[#deploy_apps] 
== Deploying Apps - Optional

If you do not plan to follow the remaining sections (which are based on deploying the demo) and prefer to play and make your own findings, simply follow the steps below:

. Create a new project:
+
[.console-input]
[source,bash,subs="attributes+,+macros"]	
----	
oc new-project test
----

. Start some applications with critical vulnerabilities:
+
[.console-input]
[source,bash,subs="attributes+,+macros"]	
----	
oc run shell --labels=app=shellshock,team=test-team \
  --image=vulnerables/cve-2014-6271 -n test
----
+
[.console-input]
[source,bash,subs="attributes+,+macros"]	
----	
oc run samba --labels=app=rce \
  --image=vulnerables/cve-2017-7494 -n test
----

. Navigate to the RHACS portal to view the violations.
